{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aVxiCZrpQqt"
      },
      "source": [
        "### **To Implement the application, run each cell step by step.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the Necessary Libraries (Ngork, Streamlit, and gdown)\n",
        "!pip install -q pyngrok\n",
        "!pip install -q streamlit\n",
        "!pip install -q streamlit_ace\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "vmuafZwx5inL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the Feature Extractor\n",
        "!gdown --id 1ExslKhLc8XV8T0S8lA2wBvHxrLs405vx"
      ],
      "metadata": {
        "id": "BQZc2VIPA59h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the K-Nearest Neighbors (KNN) Classifier\n",
        "!gdown --id 1YaSBOjD7ut6v6F4vVpK-6bGBtyMAMVlZ"
      ],
      "metadata": {
        "id": "4MuOOBYJA8kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqdv_5Fwp_8i"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "# Importing the Necessary Libraries for Loading the Models \n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "@st.cache(allow_output_mutation=True)\n",
        "\n",
        "# The Function of Loading the Hybrid CNN Model for Feature Extraction\n",
        "def load_feature_extractor():\n",
        "  network=tf.keras.models.load_model('/content/ChestVGG_SGD.h5')\n",
        "  model = tf.keras.models.Model(inputs=network.input, outputs=network.layers[41].output)\n",
        "  return model\n",
        "\n",
        "# The Function of Loading K-Nearest Neighbors (KNN) Classifier\n",
        "def load_knn():\n",
        "  with open('/content/KNN.pkl', 'rb') as file:  \n",
        "    knn = pickle.load(file)\n",
        "  return knn\n",
        "\n",
        "# Loading the Model\n",
        "with st.spinner(\"The model is being loaded...\"):\n",
        "  feature_extractor=load_feature_extractor()\n",
        "  knn=load_knn()\n",
        "\n",
        "# The Title and User Guide\n",
        "st.markdown(\"<h1 style='text-align: center; color: black;'>Pneumonia Detection in Chest X-Ray (CXR) Images</h1>\", unsafe_allow_html=True)\n",
        "st.write(\"This web application detects pneumonia cases with an accuracy of 98.55%.\")\n",
        "file = st.file_uploader(\"Please Upload a CXR Image (JPG, PNG, JPEG, or JFIF Format)\", type=[\"jpg\", \"png\", \"jpeg\", \"jfif\"])\n",
        "\n",
        "# Importing the Necessary Libraries for Loading the Input Image and Making Predicitons\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "\n",
        "# The Function of Importing the Image and Predicting Its Corresponding Class \n",
        "def import_and_predict(image_data, feature_extractor, knn):\n",
        "\n",
        "        # Preparing the Image\n",
        "        size = (224,224)    \n",
        "        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
        "        image = np.asarray(image)\n",
        "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        img=img/255.      \n",
        "        img_reshape = img[np.newaxis,...]\n",
        "\n",
        "        # Extracting Features of the Image for Predicting Using KNN Classifier\n",
        "        features_for_knn=feature_extractor.predict(img_reshape)\n",
        "\n",
        "        # Making the Prediction Using KNN Classifier\n",
        "        pred_knn = knn.predict(features_for_knn)\n",
        "\n",
        "        return pred_knn\n",
        "\n",
        "# Making the Prediciton\n",
        "if file is None:\n",
        "    st.text(\"Please upload an image file\")\n",
        "else:\n",
        "  image = Image.open(file)\n",
        "  st.image(image, use_column_width=True)\n",
        "  prediction=import_and_predict(image, feature_extractor, knn)\n",
        "  result=\"\"\n",
        "  if prediction==0:\n",
        "    st.success('Normal'.format(result))\n",
        "  if prediction==1:\n",
        "    st.success('Pneumonia'.format(result))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading Ngrok Necessary Components \n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "id": "eezQQHXL9EhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Ngrok Necessary Components\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "id": "Lyv_9Z799Ejg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPGkLrbHf4m8"
      },
      "source": [
        "### Create an Ngrok account using the following link: https://dashboard.ngrok.com/signup. \n",
        "\n",
        "### To get your Authtoken, go to the 'Your Authtoken' section in your Ngrok account and click on the 'Copy' button."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ufgbw3NfWPC"
      },
      "outputs": [],
      "source": [
        "# Use Your Authtoken ---> # Example: !./ngrok authtoken 29UX...X1\n",
        "!./ngrok authtoken <Your Authtoken>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the Application\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "katctiCT5u2k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrnAbA1jBjm_"
      },
      "source": [
        "### By Running the next cell, a public link is generated which can be used by anyone. Now, open the link with mobile phone browser, take or upload a Chest X-Ray (CXR) image, and get the output. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect('8501')\n",
        "public_url"
      ],
      "metadata": {
        "id": "xdz8vIqL5u4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Web_Application_(11) (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
